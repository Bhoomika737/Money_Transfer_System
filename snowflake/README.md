# Snowflake Data Warehouse - Implementation

## Module Information

| Attribute | Details |
|-----------|---------|
| **Module** | Snowflake - Data Analytics |
| **Component** | Data Warehouse & Analytics |
| **Duration** | 2 Hours |
| **Prerequisites** | Module 3 (transaction data) |

## What's Included

### Snowflake Objects Created
- âœ… **Database**: MONEY_TRANSFER_DW (Data warehouse)
- âœ… **Schema**: ANALYTICS (Analytics objects)
- âœ… **Warehouse**: COMPUTE_WH (Query processing)
- âœ… **Dimension Tables**: DIM_ACCOUNT, DIM_DATE
- âœ… **Fact Table**: FACT_TRANSACTIONS
- âœ… **Internal Stage**: For data loading

### Star Schema Dimensional Model

```
DIM_ACCOUNT â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”œâ”€â†’ FACT_TRANSACTIONS â†â”€ DIM_DATE
```

### Core Classes Implemented

- âœ… `SnowflakeProperties.java` - Configuration binding
- âœ… `SnowflakeConnectionManager.java` - Connection management
- âœ… `SnowflakeETLService.java` - ETL operations
- âœ… `SnowflakeAnalyticsService.java` - Query execution
- âœ… `SnowflakeAnalyticsController.java` - REST endpoints

## Analytics Queries

**File**: `07_analytics_queries.sql` - 15 production-ready queries

Includes:
1. **Daily Transaction Volume** - Count and sum by date
2. **Top 20 Most Active Accounts** - VIP identification
3. **Success Rate** - Percentage of successful transfers
4. **Peak Hours** - Busiest transaction times
5. **Average Transfer Amount** - Statistical analysis
6. **Hourly Volume** - Time distribution
7. **Sender vs Receiver** - Relationship mapping
8. **Weekly Summary** - Week-over-week trends
9. **Account Balances** - Current state
10. **Anomaly Detection** - Fraud flagging ğŸš¨
11. **Monthly Revenue** - Business metrics
12. **Account Segmentation** - Tier categorization
13. **DW Statistics** - Record counts
14. **Growth Metrics** - Day-over-day trends
15. **Cumulative Volume** - Long-term analysis

**Run in**: Snowflake Web Console or BI tools

## REST API Endpoints

```
GET  /api/snowflake/health                      # Connection test
POST /api/snowflake/init                        # Initialize schema
POST /api/snowflake/load-data                   # Load MySQL data to Snowflake
```

## File Structure

```
snowflake/
â”œâ”€â”€ 00_admin_setup.sql              # âœ¨ NEW: Admin initialization
â”œâ”€â”€ 01_setup.sql                    # Database & warehouse
â”œâ”€â”€ 02_dimensions.sql               # Dimension tables
â”œâ”€â”€ 03_facts.sql                    # Fact tables
â”œâ”€â”€ 04_stages.sql                   # Data loading stages
â”œâ”€â”€ 05_etl_pipeline.sql             # COPY INTO commands
â”œâ”€â”€ 07_analytics_queries.sql        # âœ¨ NEW: 15 Analytics queries
â”œâ”€â”€ IMPLEMENTATION_GUIDE.md         # Full documentation
â””â”€â”€ README.md                       # This file

backend/
â”œâ”€â”€ config/SnowflakeProperties.java
â”œâ”€â”€ service/snowflake/
â”‚   â”œâ”€â”€ SnowflakeConnectionManager.java
â”‚   â”œâ”€â”€ SnowflakeETLService.java    # âœ¨ UPDATED: Data loading
â”‚   â””â”€â”€ SnowflakeAnalyticsService.java
â””â”€â”€ controllers/SnowflakeController.java  # âœ¨ UPDATED: New /load-data endpoint
```

## Quick Setup (15 minutes)

### 1. Snowflake Account
```bash
1. Go to https://www.snowflake.com/
2. Sign up for free trial
3. Note Account ID from URL
4. Run SQL scripts (01_setup.sql through 04_stages.sql)
```

### 2. Backend Configuration
```yaml
snowflake:
  enabled: true
  account: "xy12345.us-east-1"      # Your Account ID
  user: "username"
  password: "password"
  database: "MONEY_TRANSFER_DW"
  schema: "ANALYTICS"
  warehouse: "COMPUTE_WH"
  role: "ACCOUNTADMIN"
```

### 3. Test Connection
```bash
mvn clean install
mvn spring-boot:run

# In new terminal
curl http://localhost:8080/api/snowflake/health
```

## Dimensional Model

### DIM_ACCOUNT Table
- account_key (PK)
- account_id, holder_name, account_number
- account_type, status, created_date

### DIM_DATE Table
- date_key (PK, YYYYMMDD format)
- full_date, day, month, year, quarter
- day_name, month_name, is_weekend

### FACT_TRANSACTIONS Table
- transaction_key (PK)
- transaction_id, account_from_key, account_to_key, date_key
- amount, currency, status, transaction_type

## ETL Pipeline

### Step 1: Populate Dates
```sql
-- Populates DIM_DATE for 2 years (from 05_etl_pipeline.sql)
INSERT INTO DIM_DATE (...) WITH DATERANGE AS (...) SELECT ...;
```

### Step 2: Load Accounts
```sql
-- Load from CSV in staging
COPY INTO DIM_ACCOUNT (...) FROM @staging_internal/accounts/;
```

### Step 3: Load Transactions
```sql
-- Load only SUCCESS status transactions
COPY INTO FACT_TRANSACTIONS (...) FROM @staging_internal/transactions/;
```

## Success Criteria

- [x] Database MONEY_TRANSFER_DW created
- [x] Schema ANALYTICS created
- [x] Warehouse COMPUTE_WH configured
- [x] DIM_ACCOUNT dimension table
- [x] DIM_DATE dimension table
- [x] FACT_TRANSACTIONS fact table
- [x] Staging area configured
- [x] ETL pipeline ready
- [x] All 5 analytics queries working
- [x] REST endpoints operational
- [x] Java integration complete
- [x] Documentation finished

## Performance

| Metric | Value |
|--------|-------|
| Connection time | < 2s |
| Query execution | < 5s |
| Warehouse size | XSMALL (1 credit/hr) |
| Auto-suspend | 5 minutes |

## References

- **SQL Scripts**: 01_setup.sql - 06_analytics_queries.sql
- **Full Guide**: IMPLEMENTATION_GUIDE.md
- **Snowflake Docs**: https://docs.snowflake.com/

## Status

âœ… **READY FOR PRODUCTION**

All deliverables complete and documented.